🌳 의사결정나무란?
데이터를 **조건(질문)**에 따라 트리 구조로 나눠가며 예측을 수행.
각 분기는 데이터의 어떤 **속성(feature)**을 기준으로 나눌지 결정.
최종 노드(잎, leaf)는 예측 결과(클래스 or 수치)를 의미.

예: 키가 170cm 이상인가? -> 예 -> 남자일 확률 높음
                       ↘ 아니오 -> 여자일 확률 높음


🧠 R에서 의사결정나무를 만드는 방법
대표 패키지:
rpart: 가장 기본적이고 널리 쓰이는 의사결정나무 패키지
rpart.plot: 시각화를 위한 패키지
(추가적으로 tree, party, randomForest도 있음)

✅ 예제: iris 데이터셋을 이용한 분류 문제
# 패키지 설치
install.packages("rpart")
install.packages("rpart.plot")

# 패키지 불러오기
library(rpart)
library(rpart.plot)

# 데이터 확인
head(iris)

# 1. 의사결정나무 모델 만들기
tree_model <- rpart(Species ~ ., data = iris, method = "class")

# 2. 트리 시각화
rpart.plot(tree_model)

# 3. 예측
predictions <- predict(tree_model, iris, type = "class")

# 4. 혼동 행렬로 정확도 평가
table(Predicted = predictions, Actual = iris$Species)

📊 결과 해석
트리의 각 노드는 어떤 조건으로 나뉘었는지 보여줍니다.
잎(leaf)에 도달하면 어떤 클래스(Species)로 예측하는지 나타납니다.
트리가 너무 복잡하면 과적합(overfitting) 위험이 있으므로 **가지치기(pruning)**를 고려할 수 있습니다.
